{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82b9d9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "X_train = pd.read_csv(\"data/x_train.txt\",header=None,sep=\" \")\n",
    "y_train = pd.read_csv(\"data/y_train.txt\",header=None,sep=\" \")\n",
    "X_train, y_train = np.array(X_train), np.array(y_train).T[0]\n",
    "def eval_proba(probas,y,n_features, num_target = 1000):\n",
    "    sorted_probas = np.sort(probas)[::-1]  \n",
    "    threshold = sorted_probas[num_target - 1]\n",
    "\n",
    "    y_pred = (probas >= threshold).astype(int)\n",
    "    gain = 10*precision_score(y, y_pred)*num_target\n",
    "    return np.round(gain - 200*n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24abe1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 6)\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 50, 'n_features': 1}, score:6986.0, features:[2]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 50, 'n_features': 2}, score:6596.0, features:[  2 414]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 50, 'n_features': 3}, score:6595.0, features:[  2 414 462]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 50, 'n_features': 4}, score:6655.0, features:[  2   4 414 462]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 50, 'n_features': 5}, score:6317.0, features:[  2   4 414 425 462]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 100, 'n_features': 1}, score:6982.0, features:[2]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 100, 'n_features': 2}, score:6620.0, features:[  2 414]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 100, 'n_features': 3}, score:6599.0, features:[  2 414 462]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 100, 'n_features': 4}, score:6646.0, features:[  2   4 414 462]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 100, 'n_features': 5}, score:6302.0, features:[  2   4 414 425 462]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 150, 'n_features': 1}, score:7020.0, features:[2]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 150, 'n_features': 2}, score:6706.0, features:[  2 414]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 150, 'n_features': 3}, score:6514.0, features:[  2 414 462]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 150, 'n_features': 4}, score:6635.0, features:[  2   4 414 462]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 150, 'n_features': 5}, score:6295.0, features:[  2   4 414 425 462]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 200, 'n_features': 1}, score:7028.0, features:[2]\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 5, 'n_estimators': 200, 'n_features': 2}, score:6687.0, features:[  2 414]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m selected = start_features[selector.get_support(indices=\u001b[38;5;28;01mTrue\u001b[39;00m)]\n\u001b[32m     31\u001b[39m X_selected = selector.transform(X_start)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m probas = \u001b[43mcross_val_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_selected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpredict_proba\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m[:,\u001b[32m1\u001b[39m]\n\u001b[32m     33\u001b[39m score = eval_proba(probas, y_train,params[\u001b[33m'\u001b[39m\u001b[33mn_features\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mParams: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, score:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, features:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Micha\\anaconda3\\envs\\idp\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Micha\\anaconda3\\envs\\idp\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1247\u001b[39m, in \u001b[36mcross_val_predict\u001b[39m\u001b[34m(estimator, X, y, groups, cv, n_jobs, verbose, params, pre_dispatch, method)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m   1245\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m   1246\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m predictions = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1260\u001b[39m inv_test_indices = np.empty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype=\u001b[38;5;28mint\u001b[39m)\n\u001b[32m   1261\u001b[39m inv_test_indices[test_indices] = np.arange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Micha\\anaconda3\\envs\\idp\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Micha\\anaconda3\\envs\\idp\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Micha\\anaconda3\\envs\\idp\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Micha\\anaconda3\\envs\\idp\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Micha\\anaconda3\\envs\\idp\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1332\u001b[39m, in \u001b[36m_fit_and_predict\u001b[39m\u001b[34m(estimator, X, y, train, test, fit_params, method)\u001b[39m\n\u001b[32m   1330\u001b[39m     estimator.fit(X_train, **fit_params)\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1332\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1333\u001b[39m func = \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[32m   1334\u001b[39m predictions = func(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Micha\\anaconda3\\envs\\idp\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Micha\\anaconda3\\envs\\idp\\Lib\\site-packages\\xgboost\\sklearn.py:1682\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1660\u001b[39m model, metric, params, feature_weights = \u001b[38;5;28mself\u001b[39m._configure_fit(\n\u001b[32m   1661\u001b[39m     xgb_model, params, feature_weights\n\u001b[32m   1662\u001b[39m )\n\u001b[32m   1663\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1664\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1665\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1679\u001b[39m     feature_types=\u001b[38;5;28mself\u001b[39m.feature_types,\n\u001b[32m   1680\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1685\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1696\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1697\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Micha\\anaconda3\\envs\\idp\\Lib\\site-packages\\xgboost\\core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Micha\\anaconda3\\envs\\idp\\Lib\\site-packages\\xgboost\\training.py:183\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Micha\\anaconda3\\envs\\idp\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2243\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2246\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2247\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2250\u001b[39m     )\n\u001b[32m   2251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2252\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_predict\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [5,10, 15, 25],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "    'n_features': [1, 2, 3, 4, 5]\n",
    "}\n",
    "#Choosen based on previous test\n",
    "start_features = np.array([2,  4,  5, 414, 425, 462])\n",
    "best_score = 0\n",
    "best_params = None\n",
    "history = []\n",
    "X_start = X_train[:,start_features]\n",
    "for params in ParameterGrid(param_grid):\n",
    "    \n",
    "    model = XGBClassifier(n_estimators=params['n_estimators'],\n",
    "            max_depth=params['max_depth'],\n",
    "            learning_rate=params['learning_rate'], \n",
    "            objective='binary:logistic',\n",
    "            random_state=42,\n",
    "            n_jobs=-1)\n",
    "    \n",
    "    selector = RFE(estimator=model, n_features_to_select=params['n_features'], step=1, verbose=0)\n",
    "    selector.fit(X_start, y_train)\n",
    "    selected = start_features[selector.get_support(indices=True)]\n",
    "    X_selected = selector.transform(X_start)\n",
    "    probas = cross_val_predict(model, X_selected, y_train,  method='predict_proba')[:,1]\n",
    "    score = eval_proba(probas, y_train,params['n_features'])\n",
    "    print(f\"Params: {params}, score:{score}, features:{selected}\")\n",
    "\n",
    "    history.append({**params,\n",
    "                    \"score\": score,\n",
    "                    \"features\":selected})\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "        best_features = selected\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Max gain: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ce38ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "5d257aed-b114-4438-b36c-8444b00634b1",
       "rows": [
        [
         "0",
         "20.4546467389865",
         "16.7393450975877",
         "39.8118922391184"
        ],
        [
         "1",
         "16.1752254461845",
         "10.4832811104721",
         "27.4710172278915"
        ],
        [
         "2",
         "10.577211680538",
         "10.7951145669734",
         "24.6213877127776"
        ],
        [
         "3",
         "26.2992059591802",
         "13.4712151717437",
         "51.7259337210708"
        ],
        [
         "4",
         "23.193955168834",
         "20.0379686987164",
         "37.7802895554531"
        ],
        [
         "5",
         "24.8875112350124",
         "18.7787875834174",
         "47.5592941237174"
        ],
        [
         "6",
         "4.42667606247377",
         "3.97554605576809",
         "9.36101575097885"
        ],
        [
         "7",
         "19.0445447723522",
         "12.0722507982493",
         "35.3602809063677"
        ],
        [
         "8",
         "9.8558353474514",
         "9.9732926105505",
         "18.3280121808873"
        ],
        [
         "9",
         "9.26041927234612",
         "9.65162505073318",
         "22.2405939993751"
        ],
        [
         "10",
         "19.3995531013597",
         "17.0649333368689",
         "42.2590935205955"
        ],
        [
         "11",
         "10.4164849444996",
         "10.768269531434",
         "18.968890933913"
        ],
        [
         "12",
         "9.01985446129786",
         "7.01098212459249",
         "23.5434868447087"
        ],
        [
         "13",
         "11.1091020773261",
         "8.85462215939557",
         "17.4887905435709"
        ],
        [
         "14",
         "14.6811664852136",
         "15.3714690026658",
         "27.5464098218097"
        ],
        [
         "15",
         "16.8805894861983",
         "8.85007439784395",
         "27.5932978304173"
        ],
        [
         "16",
         "11.0751673485892",
         "8.17928220145646",
         "20.2471586772704"
        ],
        [
         "17",
         "22.6721373598321",
         "17.2004655705779",
         "43.1356340450233"
        ],
        [
         "18",
         "20.5677813985321",
         "17.5479034251784",
         "35.0594999519591"
        ],
        [
         "19",
         "10.4867876351535",
         "7.49596821421995",
         "24.3523874564346"
        ],
        [
         "20",
         "19.3025097202494",
         "13.7039141785536",
         "32.8204850554526"
        ],
        [
         "21",
         "18.7646149602084",
         "18.0373928641555",
         "34.5025677821803"
        ],
        [
         "22",
         "13.7316005615939",
         "11.0794551621324",
         "23.7348063068382"
        ],
        [
         "23",
         "8.55389870380689",
         "6.90972459014555",
         "20.6086007133913"
        ],
        [
         "24",
         "14.498487939874",
         "13.0314228672483",
         "25.3079397757104"
        ],
        [
         "25",
         "29.2480300839531",
         "25.5285042850704",
         "52.8804040761019"
        ],
        [
         "26",
         "7.61175552491686",
         "7.88024362618037",
         "16.7278720440305"
        ],
        [
         "27",
         "10.5112166764844",
         "7.28319295490458",
         "17.3262534088828"
        ],
        [
         "28",
         "12.6907117703648",
         "12.8273317085338",
         "22.6837492609764"
        ],
        [
         "29",
         "11.8979870559965",
         "8.71633874512492",
         "22.4077722527016"
        ],
        [
         "30",
         "21.2734974324732",
         "22.2669207269991",
         "36.8856905009446"
        ],
        [
         "31",
         "10.5304472203227",
         "8.49383387838316",
         "23.7753234355463"
        ],
        [
         "32",
         "18.6940980737283",
         "14.4682553118256",
         "29.1069365946569"
        ],
        [
         "33",
         "13.8984161996949",
         "11.4256699931823",
         "27.3577448736348"
        ],
        [
         "34",
         "8.78128591418627",
         "6.54403835571053",
         "13.4493604364331"
        ],
        [
         "35",
         "18.3432060991952",
         "15.63839210378",
         "29.8846210154317"
        ],
        [
         "36",
         "18.4734235717194",
         "16.5963950569539",
         "36.09677361221"
        ],
        [
         "37",
         "19.861966700632",
         "16.7125342615382",
         "39.8617355853314"
        ],
        [
         "38",
         "11.4052211778954",
         "9.12980028642339",
         "23.2985140745176"
        ],
        [
         "39",
         "9.51092203116944",
         "7.00497488240104",
         "15.6188074245692"
        ],
        [
         "40",
         "14.9483719346761",
         "13.8338388840273",
         "24.7935003542414"
        ],
        [
         "41",
         "14.931250618537",
         "12.1569167033049",
         "38.6500359562457"
        ],
        [
         "42",
         "12.799168936423",
         "10.6701099346109",
         "17.2267431078406"
        ],
        [
         "43",
         "13.1555046001204",
         "12.6897470892995",
         "27.8954272174648"
        ],
        [
         "44",
         "12.9770949806076",
         "14.260307957566",
         "26.3013954709987"
        ],
        [
         "45",
         "18.3823367365176",
         "15.1365364737854",
         "30.9182521868388"
        ],
        [
         "46",
         "10.6549803032628",
         "7.58353015142631",
         "21.1234392929844"
        ],
        [
         "47",
         "12.8093507547523",
         "9.73781683283929",
         "34.900396297489"
        ],
        [
         "48",
         "14.5026452409991",
         "9.37072845506022",
         "24.2361445288813"
        ],
        [
         "49",
         "12.1345871791227",
         "12.6578928874009",
         "29.7471149770657"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.454647</td>\n",
       "      <td>16.739345</td>\n",
       "      <td>39.811892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.175225</td>\n",
       "      <td>10.483281</td>\n",
       "      <td>27.471017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.577212</td>\n",
       "      <td>10.795115</td>\n",
       "      <td>24.621388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.299206</td>\n",
       "      <td>13.471215</td>\n",
       "      <td>51.725934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.193955</td>\n",
       "      <td>20.037969</td>\n",
       "      <td>37.780290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>22.390013</td>\n",
       "      <td>15.116628</td>\n",
       "      <td>25.835180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>15.482546</td>\n",
       "      <td>14.319951</td>\n",
       "      <td>31.035257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>10.607588</td>\n",
       "      <td>8.713746</td>\n",
       "      <td>17.567374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>22.984365</td>\n",
       "      <td>13.822107</td>\n",
       "      <td>30.838448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>14.467288</td>\n",
       "      <td>10.507709</td>\n",
       "      <td>24.687623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1          2\n",
       "0     20.454647  16.739345  39.811892\n",
       "1     16.175225  10.483281  27.471017\n",
       "2     10.577212  10.795115  24.621388\n",
       "3     26.299206  13.471215  51.725934\n",
       "4     23.193955  20.037969  37.780290\n",
       "...         ...        ...        ...\n",
       "4995  22.390013  15.116628  25.835180\n",
       "4996  15.482546  14.319951  31.035257\n",
       "4997  10.607588   8.713746  17.567374\n",
       "4998  22.984365  13.822107  30.838448\n",
       "4999  14.467288  10.507709  24.687623\n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[[0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c91932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 50, 'n_features': 1}, gain: 1227.00, precision: 0.712, f1: 0.498, accuracy: 0.630\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 50, 'n_features': 2}, gain: 1057.00, precision: 0.719, f1: 0.518, accuracy: 0.633\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 50, 'n_features': 3}, gain: 835.60, precision: 0.711, f1: 0.503, accuracy: 0.628\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 50, 'n_features': 4}, gain: 632.40, precision: 0.719, f1: 0.587, accuracy: 0.661\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 50, 'n_features': 5}, gain: 430.00, precision: 0.707, f1: 0.566, accuracy: 0.650\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 50, 'n_features': 6}, gain: 242.20, precision: 0.713, f1: 0.572, accuracy: 0.653\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 100, 'n_features': 1}, gain: 1250.40, precision: 0.714, f1: 0.670, accuracy: 0.696\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 100, 'n_features': 2}, gain: 1056.00, precision: 0.711, f1: 0.657, accuracy: 0.689\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 100, 'n_features': 3}, gain: 842.00, precision: 0.718, f1: 0.673, accuracy: 0.699\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 100, 'n_features': 4}, gain: 615.60, precision: 0.714, f1: 0.679, accuracy: 0.701\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 100, 'n_features': 5}, gain: 419.40, precision: 0.717, f1: 0.682, accuracy: 0.704\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 100, 'n_features': 6}, gain: 238.80, precision: 0.717, f1: 0.680, accuracy: 0.703\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 150, 'n_features': 1}, gain: 1247.60, precision: 0.709, f1: 0.674, accuracy: 0.696\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 150, 'n_features': 2}, gain: 1049.80, precision: 0.710, f1: 0.676, accuracy: 0.698\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 150, 'n_features': 3}, gain: 834.40, precision: 0.716, f1: 0.678, accuracy: 0.701\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 150, 'n_features': 4}, gain: 618.40, precision: 0.712, f1: 0.687, accuracy: 0.704\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 150, 'n_features': 5}, gain: 430.40, precision: 0.717, f1: 0.691, accuracy: 0.709\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 150, 'n_features': 6}, gain: 232.20, precision: 0.715, f1: 0.690, accuracy: 0.707\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 200, 'n_features': 1}, gain: 1249.40, precision: 0.705, f1: 0.677, accuracy: 0.696\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 200, 'n_features': 2}, gain: 1046.40, precision: 0.707, f1: 0.681, accuracy: 0.699\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 200, 'n_features': 3}, gain: 832.20, precision: 0.713, f1: 0.684, accuracy: 0.703\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 200, 'n_features': 4}, gain: 616.00, precision: 0.711, f1: 0.692, accuracy: 0.707\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 200, 'n_features': 5}, gain: 430.00, precision: 0.714, f1: 0.699, accuracy: 0.712\n",
      "Params: {'learning_rate': 0.001, 'max_depth': None, 'n_estimators': 200, 'n_features': 6}, gain: 229.60, precision: 0.712, f1: 0.694, accuracy: 0.708\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 50, 'n_features': 1}, gain: 1236.40, precision: 0.714, f1: 0.521, accuracy: 0.637\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 50, 'n_features': 2}, gain: 1021.60, precision: 0.709, f1: 0.523, accuracy: 0.631\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 50, 'n_features': 3}, gain: 826.20, precision: 0.701, f1: 0.534, accuracy: 0.632\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 50, 'n_features': 4}, gain: 659.80, precision: 0.700, f1: 0.518, accuracy: 0.626\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 50, 'n_features': 5}, gain: 469.00, precision: 0.713, f1: 0.528, accuracy: 0.634\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 50, 'n_features': 6}, gain: 254.20, precision: 0.706, f1: 0.514, accuracy: 0.627\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 100, 'n_features': 1}, gain: 1256.60, precision: 0.713, f1: 0.662, accuracy: 0.692\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 100, 'n_features': 2}, gain: 1016.20, precision: 0.668, f1: 0.587, accuracy: 0.640\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 100, 'n_features': 3}, gain: 816.00, precision: 0.673, f1: 0.590, accuracy: 0.643\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 100, 'n_features': 4}, gain: 666.40, precision: 0.674, f1: 0.594, accuracy: 0.645\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 100, 'n_features': 5}, gain: 444.60, precision: 0.683, f1: 0.588, accuracy: 0.647\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 100, 'n_features': 6}, gain: 243.60, precision: 0.679, f1: 0.579, accuracy: 0.642\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 150, 'n_features': 1}, gain: 1259.80, precision: 0.702, f1: 0.666, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 150, 'n_features': 2}, gain: 1026.40, precision: 0.656, f1: 0.601, accuracy: 0.640\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 150, 'n_features': 3}, gain: 821.80, precision: 0.671, f1: 0.615, accuracy: 0.653\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 150, 'n_features': 4}, gain: 649.80, precision: 0.669, f1: 0.622, accuracy: 0.655\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 150, 'n_features': 5}, gain: 434.00, precision: 0.677, f1: 0.620, accuracy: 0.657\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 150, 'n_features': 6}, gain: 244.60, precision: 0.680, f1: 0.619, accuracy: 0.659\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 200, 'n_features': 1}, gain: 1251.40, precision: 0.701, f1: 0.670, accuracy: 0.692\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 200, 'n_features': 2}, gain: 1024.40, precision: 0.653, f1: 0.616, accuracy: 0.645\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 200, 'n_features': 3}, gain: 822.20, precision: 0.663, f1: 0.624, accuracy: 0.654\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 200, 'n_features': 4}, gain: 658.00, precision: 0.662, f1: 0.632, accuracy: 0.656\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 200, 'n_features': 5}, gain: 432.00, precision: 0.671, f1: 0.630, accuracy: 0.659\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 200, 'n_features': 6}, gain: 234.60, precision: 0.674, f1: 0.633, accuracy: 0.662\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 50, 'n_features': 1}, gain: 1236.40, precision: 0.714, f1: 0.521, accuracy: 0.637\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 50, 'n_features': 2}, gain: 1007.60, precision: 0.710, f1: 0.531, accuracy: 0.634\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 50, 'n_features': 3}, gain: 808.80, precision: 0.705, f1: 0.543, accuracy: 0.637\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 50, 'n_features': 4}, gain: 644.80, precision: 0.704, f1: 0.527, accuracy: 0.631\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 50, 'n_features': 5}, gain: 463.20, precision: 0.715, f1: 0.535, accuracy: 0.637\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 50, 'n_features': 6}, gain: 241.60, precision: 0.708, f1: 0.516, accuracy: 0.628\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100, 'n_features': 1}, gain: 1256.60, precision: 0.713, f1: 0.662, accuracy: 0.692\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100, 'n_features': 2}, gain: 1019.60, precision: 0.672, f1: 0.594, accuracy: 0.644\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100, 'n_features': 3}, gain: 820.60, precision: 0.679, f1: 0.603, accuracy: 0.652\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100, 'n_features': 4}, gain: 642.00, precision: 0.682, f1: 0.603, accuracy: 0.652\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100, 'n_features': 5}, gain: 435.80, precision: 0.695, f1: 0.609, accuracy: 0.660\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 100, 'n_features': 6}, gain: 234.40, precision: 0.687, f1: 0.595, accuracy: 0.652\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 150, 'n_features': 1}, gain: 1254.00, precision: 0.702, f1: 0.666, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 150, 'n_features': 2}, gain: 1026.40, precision: 0.661, f1: 0.610, accuracy: 0.646\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 150, 'n_features': 3}, gain: 813.80, precision: 0.674, f1: 0.624, accuracy: 0.658\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 150, 'n_features': 4}, gain: 631.20, precision: 0.678, f1: 0.631, accuracy: 0.663\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 150, 'n_features': 5}, gain: 448.00, precision: 0.689, f1: 0.632, accuracy: 0.668\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 150, 'n_features': 6}, gain: 228.00, precision: 0.683, f1: 0.626, accuracy: 0.663\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 200, 'n_features': 1}, gain: 1247.20, precision: 0.701, f1: 0.670, accuracy: 0.692\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 200, 'n_features': 2}, gain: 1022.00, precision: 0.656, f1: 0.622, accuracy: 0.649\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 200, 'n_features': 3}, gain: 830.80, precision: 0.672, f1: 0.637, accuracy: 0.663\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 200, 'n_features': 4}, gain: 637.60, precision: 0.673, f1: 0.643, accuracy: 0.666\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 200, 'n_features': 5}, gain: 446.00, precision: 0.685, f1: 0.644, accuracy: 0.672\n",
      "Params: {'learning_rate': 0.001, 'max_depth': 15, 'n_estimators': 200, 'n_features': 6}, gain: 230.60, precision: 0.679, f1: 0.642, accuracy: 0.669\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 50, 'n_features': 1}, gain: 1234.40, precision: 0.700, f1: 0.682, accuracy: 0.697\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 50, 'n_features': 2}, gain: 1040.20, precision: 0.698, f1: 0.687, accuracy: 0.699\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 50, 'n_features': 3}, gain: 840.80, precision: 0.705, f1: 0.692, accuracy: 0.705\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 50, 'n_features': 4}, gain: 642.00, precision: 0.711, f1: 0.702, accuracy: 0.712\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 50, 'n_features': 5}, gain: 448.60, precision: 0.711, f1: 0.704, accuracy: 0.714\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 50, 'n_features': 6}, gain: 261.00, precision: 0.711, f1: 0.700, accuracy: 0.711\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100, 'n_features': 1}, gain: 1218.00, precision: 0.699, f1: 0.684, accuracy: 0.698\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100, 'n_features': 2}, gain: 1039.80, precision: 0.697, f1: 0.692, accuracy: 0.701\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100, 'n_features': 3}, gain: 830.80, precision: 0.706, f1: 0.700, accuracy: 0.709\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100, 'n_features': 4}, gain: 658.60, precision: 0.713, f1: 0.707, accuracy: 0.716\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100, 'n_features': 5}, gain: 439.80, precision: 0.711, f1: 0.706, accuracy: 0.715\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100, 'n_features': 6}, gain: 272.40, precision: 0.712, f1: 0.705, accuracy: 0.714\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 150, 'n_features': 1}, gain: 1237.20, precision: 0.695, f1: 0.685, accuracy: 0.696\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 150, 'n_features': 2}, gain: 1022.20, precision: 0.694, f1: 0.694, accuracy: 0.701\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 150, 'n_features': 3}, gain: 837.00, precision: 0.706, f1: 0.700, accuracy: 0.709\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 150, 'n_features': 4}, gain: 666.00, precision: 0.711, f1: 0.705, accuracy: 0.714\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 150, 'n_features': 5}, gain: 466.00, precision: 0.714, f1: 0.708, accuracy: 0.717\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 150, 'n_features': 6}, gain: 280.40, precision: 0.713, f1: 0.709, accuracy: 0.717\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 200, 'n_features': 1}, gain: 1234.60, precision: 0.694, f1: 0.690, accuracy: 0.699\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 200, 'n_features': 2}, gain: 1035.60, precision: 0.695, f1: 0.695, accuracy: 0.702\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 200, 'n_features': 3}, gain: 837.60, precision: 0.705, f1: 0.700, accuracy: 0.709\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 200, 'n_features': 4}, gain: 662.40, precision: 0.709, f1: 0.703, accuracy: 0.712\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 200, 'n_features': 5}, gain: 484.00, precision: 0.714, f1: 0.709, accuracy: 0.717\n",
      "Params: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 200, 'n_features': 6}, gain: 279.40, precision: 0.712, f1: 0.710, accuracy: 0.717\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50, 'n_features': 1}, gain: 1213.00, precision: 0.689, f1: 0.678, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50, 'n_features': 2}, gain: 1003.20, precision: 0.659, f1: 0.645, accuracy: 0.660\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50, 'n_features': 3}, gain: 842.00, precision: 0.662, f1: 0.649, accuracy: 0.664\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50, 'n_features': 4}, gain: 650.00, precision: 0.672, f1: 0.659, accuracy: 0.673\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50, 'n_features': 5}, gain: 436.00, precision: 0.677, f1: 0.658, accuracy: 0.675\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 50, 'n_features': 6}, gain: 256.00, precision: 0.673, f1: 0.660, accuracy: 0.674\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100, 'n_features': 1}, gain: 1246.00, precision: 0.688, f1: 0.678, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100, 'n_features': 2}, gain: 1002.60, precision: 0.652, f1: 0.651, accuracy: 0.659\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100, 'n_features': 3}, gain: 834.00, precision: 0.664, f1: 0.658, accuracy: 0.669\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100, 'n_features': 4}, gain: 652.00, precision: 0.672, f1: 0.665, accuracy: 0.676\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100, 'n_features': 5}, gain: 458.00, precision: 0.682, f1: 0.669, accuracy: 0.682\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 100, 'n_features': 6}, gain: 246.00, precision: 0.678, f1: 0.672, accuracy: 0.682\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 150, 'n_features': 1}, gain: 1253.00, precision: 0.689, f1: 0.678, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 150, 'n_features': 2}, gain: 994.00, precision: 0.642, f1: 0.646, accuracy: 0.652\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 150, 'n_features': 3}, gain: 836.00, precision: 0.665, f1: 0.657, accuracy: 0.669\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 150, 'n_features': 4}, gain: 678.00, precision: 0.673, f1: 0.669, accuracy: 0.679\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 150, 'n_features': 5}, gain: 464.00, precision: 0.681, f1: 0.670, accuracy: 0.683\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 150, 'n_features': 6}, gain: 260.00, precision: 0.680, f1: 0.677, accuracy: 0.686\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200, 'n_features': 1}, gain: 1248.20, precision: 0.689, f1: 0.678, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200, 'n_features': 2}, gain: 1002.00, precision: 0.641, f1: 0.646, accuracy: 0.651\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200, 'n_features': 3}, gain: 822.00, precision: 0.658, f1: 0.655, accuracy: 0.665\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200, 'n_features': 4}, gain: 656.00, precision: 0.673, f1: 0.671, accuracy: 0.680\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200, 'n_features': 5}, gain: 478.00, precision: 0.679, f1: 0.667, accuracy: 0.680\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 25, 'n_estimators': 200, 'n_features': 6}, gain: 262.00, precision: 0.680, f1: 0.678, accuracy: 0.686\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50, 'n_features': 1}, gain: 1208.00, precision: 0.689, f1: 0.678, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50, 'n_features': 2}, gain: 1014.80, precision: 0.664, f1: 0.651, accuracy: 0.665\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50, 'n_features': 3}, gain: 838.00, precision: 0.670, f1: 0.657, accuracy: 0.671\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50, 'n_features': 4}, gain: 626.00, precision: 0.675, f1: 0.664, accuracy: 0.677\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50, 'n_features': 5}, gain: 457.20, precision: 0.685, f1: 0.668, accuracy: 0.684\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 50, 'n_features': 6}, gain: 264.00, precision: 0.681, f1: 0.668, accuracy: 0.682\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100, 'n_features': 1}, gain: 1245.60, precision: 0.688, f1: 0.678, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100, 'n_features': 2}, gain: 996.80, precision: 0.663, f1: 0.658, accuracy: 0.668\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100, 'n_features': 3}, gain: 832.00, precision: 0.668, f1: 0.663, accuracy: 0.673\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100, 'n_features': 4}, gain: 644.00, precision: 0.683, f1: 0.675, accuracy: 0.686\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100, 'n_features': 5}, gain: 480.00, precision: 0.693, f1: 0.679, accuracy: 0.692\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 100, 'n_features': 6}, gain: 270.00, precision: 0.690, f1: 0.680, accuracy: 0.691\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 150, 'n_features': 1}, gain: 1252.20, precision: 0.688, f1: 0.678, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 150, 'n_features': 2}, gain: 1001.20, precision: 0.664, f1: 0.664, accuracy: 0.672\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 150, 'n_features': 3}, gain: 830.60, precision: 0.672, f1: 0.667, accuracy: 0.677\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 150, 'n_features': 4}, gain: 656.00, precision: 0.682, f1: 0.678, accuracy: 0.688\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 150, 'n_features': 5}, gain: 482.00, precision: 0.694, f1: 0.684, accuracy: 0.695\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 150, 'n_features': 6}, gain: 296.00, precision: 0.692, f1: 0.685, accuracy: 0.695\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200, 'n_features': 1}, gain: 1245.60, precision: 0.688, f1: 0.678, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200, 'n_features': 2}, gain: 994.60, precision: 0.665, f1: 0.666, accuracy: 0.673\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200, 'n_features': 3}, gain: 812.00, precision: 0.670, f1: 0.667, accuracy: 0.676\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200, 'n_features': 4}, gain: 676.00, precision: 0.683, f1: 0.682, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200, 'n_features': 5}, gain: 476.00, precision: 0.693, f1: 0.685, accuracy: 0.696\n",
      "Params: {'learning_rate': 0.01, 'max_depth': 15, 'n_estimators': 200, 'n_features': 6}, gain: 282.00, precision: 0.690, f1: 0.685, accuracy: 0.695\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 50, 'n_features': 1}, gain: 1233.80, precision: 0.694, f1: 0.689, accuracy: 0.698\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 50, 'n_features': 2}, gain: 1034.20, precision: 0.692, f1: 0.693, accuracy: 0.700\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 50, 'n_features': 3}, gain: 824.60, precision: 0.703, f1: 0.699, accuracy: 0.707\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 50, 'n_features': 4}, gain: 666.00, precision: 0.709, f1: 0.703, accuracy: 0.712\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 50, 'n_features': 5}, gain: 480.00, precision: 0.711, f1: 0.707, accuracy: 0.716\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 50, 'n_features': 6}, gain: 291.00, precision: 0.712, f1: 0.708, accuracy: 0.716\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 100, 'n_features': 1}, gain: 1230.60, precision: 0.692, f1: 0.690, accuracy: 0.698\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 100, 'n_features': 2}, gain: 1001.60, precision: 0.688, f1: 0.691, accuracy: 0.697\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 100, 'n_features': 3}, gain: 836.00, precision: 0.700, f1: 0.698, accuracy: 0.706\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 100, 'n_features': 4}, gain: 678.00, precision: 0.708, f1: 0.701, accuracy: 0.711\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 100, 'n_features': 5}, gain: 464.00, precision: 0.708, f1: 0.704, accuracy: 0.713\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 100, 'n_features': 6}, gain: 268.00, precision: 0.711, f1: 0.707, accuracy: 0.715\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 150, 'n_features': 1}, gain: 1248.00, precision: 0.692, f1: 0.690, accuracy: 0.698\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 150, 'n_features': 2}, gain: 1000.00, precision: 0.687, f1: 0.688, accuracy: 0.695\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 150, 'n_features': 3}, gain: 844.00, precision: 0.698, f1: 0.695, accuracy: 0.703\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 150, 'n_features': 4}, gain: 674.00, precision: 0.704, f1: 0.697, accuracy: 0.707\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 150, 'n_features': 5}, gain: 448.00, precision: 0.707, f1: 0.703, accuracy: 0.712\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 150, 'n_features': 6}, gain: 262.00, precision: 0.707, f1: 0.704, accuracy: 0.712\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 200, 'n_features': 1}, gain: 1250.00, precision: 0.692, f1: 0.690, accuracy: 0.698\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 200, 'n_features': 2}, gain: 1012.80, precision: 0.685, f1: 0.685, accuracy: 0.692\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 200, 'n_features': 3}, gain: 836.00, precision: 0.695, f1: 0.691, accuracy: 0.700\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 200, 'n_features': 4}, gain: 700.00, precision: 0.701, f1: 0.694, accuracy: 0.704\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 200, 'n_features': 5}, gain: 454.00, precision: 0.704, f1: 0.701, accuracy: 0.709\n",
      "Params: {'learning_rate': 0.05, 'max_depth': None, 'n_estimators': 200, 'n_features': 6}, gain: 268.00, precision: 0.705, f1: 0.701, accuracy: 0.709\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 50, 'n_features': 1}, gain: 1249.20, precision: 0.689, f1: 0.678, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 50, 'n_features': 2}, gain: 976.00, precision: 0.638, f1: 0.644, accuracy: 0.649\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 50, 'n_features': 3}, gain: 812.00, precision: 0.661, f1: 0.657, accuracy: 0.667\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 50, 'n_features': 4}, gain: 654.00, precision: 0.666, f1: 0.664, accuracy: 0.673\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 50, 'n_features': 5}, gain: 474.00, precision: 0.679, f1: 0.669, accuracy: 0.682\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 50, 'n_features': 6}, gain: 302.00, precision: 0.681, f1: 0.679, accuracy: 0.687\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 100, 'n_features': 1}, gain: 1246.20, precision: 0.689, f1: 0.678, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 100, 'n_features': 2}, gain: 966.00, precision: 0.636, f1: 0.642, accuracy: 0.647\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 100, 'n_features': 3}, gain: 816.60, precision: 0.655, f1: 0.651, accuracy: 0.661\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 100, 'n_features': 4}, gain: 672.00, precision: 0.667, f1: 0.664, accuracy: 0.673\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 100, 'n_features': 5}, gain: 486.00, precision: 0.678, f1: 0.668, accuracy: 0.680\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 100, 'n_features': 6}, gain: 292.00, precision: 0.679, f1: 0.680, accuracy: 0.687\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 150, 'n_features': 1}, gain: 1246.20, precision: 0.689, f1: 0.680, accuracy: 0.691\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 150, 'n_features': 2}, gain: 972.00, precision: 0.632, f1: 0.635, accuracy: 0.642\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 150, 'n_features': 3}, gain: 820.00, precision: 0.650, f1: 0.646, accuracy: 0.656\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 150, 'n_features': 4}, gain: 676.00, precision: 0.660, f1: 0.654, accuracy: 0.665\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 150, 'n_features': 5}, gain: 484.00, precision: 0.676, f1: 0.665, accuracy: 0.678\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 150, 'n_features': 6}, gain: 302.00, precision: 0.679, f1: 0.677, accuracy: 0.685\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 200, 'n_features': 1}, gain: 1247.80, precision: 0.687, f1: 0.682, accuracy: 0.691\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 200, 'n_features': 2}, gain: 978.00, precision: 0.628, f1: 0.633, accuracy: 0.638\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 200, 'n_features': 3}, gain: 814.00, precision: 0.647, f1: 0.642, accuracy: 0.653\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 200, 'n_features': 4}, gain: 672.00, precision: 0.661, f1: 0.654, accuracy: 0.666\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 200, 'n_features': 5}, gain: 484.00, precision: 0.676, f1: 0.666, accuracy: 0.678\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 25, 'n_estimators': 200, 'n_features': 6}, gain: 298.00, precision: 0.678, f1: 0.677, accuracy: 0.684\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 50, 'n_features': 1}, gain: 1247.20, precision: 0.689, f1: 0.678, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 50, 'n_features': 2}, gain: 1000.60, precision: 0.659, f1: 0.663, accuracy: 0.669\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 50, 'n_features': 3}, gain: 838.00, precision: 0.675, f1: 0.673, accuracy: 0.681\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 50, 'n_features': 4}, gain: 662.00, precision: 0.683, f1: 0.680, accuracy: 0.689\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 50, 'n_features': 5}, gain: 482.00, precision: 0.690, f1: 0.682, accuracy: 0.693\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 50, 'n_features': 6}, gain: 286.00, precision: 0.690, f1: 0.688, accuracy: 0.696\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 100, 'n_features': 1}, gain: 1247.60, precision: 0.689, f1: 0.678, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 100, 'n_features': 2}, gain: 972.00, precision: 0.655, f1: 0.658, accuracy: 0.664\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 100, 'n_features': 3}, gain: 828.00, precision: 0.673, f1: 0.670, accuracy: 0.679\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 100, 'n_features': 4}, gain: 654.00, precision: 0.677, f1: 0.671, accuracy: 0.681\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 100, 'n_features': 5}, gain: 472.00, precision: 0.691, f1: 0.683, accuracy: 0.694\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 100, 'n_features': 6}, gain: 284.00, precision: 0.690, f1: 0.688, accuracy: 0.696\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 150, 'n_features': 1}, gain: 1246.80, precision: 0.688, f1: 0.679, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 150, 'n_features': 2}, gain: 972.00, precision: 0.650, f1: 0.652, accuracy: 0.659\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 150, 'n_features': 3}, gain: 836.00, precision: 0.667, f1: 0.664, accuracy: 0.673\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 150, 'n_features': 4}, gain: 650.00, precision: 0.672, f1: 0.668, accuracy: 0.678\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 150, 'n_features': 5}, gain: 466.00, precision: 0.688, f1: 0.680, accuracy: 0.691\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 150, 'n_features': 6}, gain: 270.00, precision: 0.687, f1: 0.683, accuracy: 0.692\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 200, 'n_features': 1}, gain: 1246.20, precision: 0.687, f1: 0.682, accuracy: 0.691\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 200, 'n_features': 2}, gain: 984.00, precision: 0.642, f1: 0.647, accuracy: 0.653\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 200, 'n_features': 3}, gain: 824.00, precision: 0.664, f1: 0.661, accuracy: 0.670\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 200, 'n_features': 4}, gain: 646.00, precision: 0.674, f1: 0.670, accuracy: 0.679\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 200, 'n_features': 5}, gain: 478.00, precision: 0.684, f1: 0.674, accuracy: 0.686\n",
      "Params: {'learning_rate': 0.05, 'max_depth': 15, 'n_estimators': 200, 'n_features': 6}, gain: 276.00, precision: 0.685, f1: 0.681, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 50, 'n_features': 1}, gain: 1235.00, precision: 0.693, f1: 0.689, accuracy: 0.698\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 50, 'n_features': 2}, gain: 1015.80, precision: 0.691, f1: 0.693, accuracy: 0.699\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 50, 'n_features': 3}, gain: 847.60, precision: 0.703, f1: 0.699, accuracy: 0.708\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 50, 'n_features': 4}, gain: 696.00, precision: 0.706, f1: 0.700, accuracy: 0.709\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 50, 'n_features': 5}, gain: 464.00, precision: 0.709, f1: 0.707, accuracy: 0.715\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 50, 'n_features': 6}, gain: 284.00, precision: 0.709, f1: 0.708, accuracy: 0.715\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 100, 'n_features': 1}, gain: 1255.60, precision: 0.692, f1: 0.687, accuracy: 0.696\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 100, 'n_features': 2}, gain: 1014.60, precision: 0.685, f1: 0.685, accuracy: 0.692\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 100, 'n_features': 3}, gain: 856.00, precision: 0.695, f1: 0.690, accuracy: 0.699\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 100, 'n_features': 4}, gain: 688.00, precision: 0.701, f1: 0.694, accuracy: 0.704\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 100, 'n_features': 5}, gain: 474.00, precision: 0.704, f1: 0.698, accuracy: 0.707\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 100, 'n_features': 6}, gain: 264.00, precision: 0.702, f1: 0.701, accuracy: 0.708\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 150, 'n_features': 1}, gain: 1245.80, precision: 0.692, f1: 0.688, accuracy: 0.697\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 150, 'n_features': 2}, gain: 1008.00, precision: 0.686, f1: 0.682, accuracy: 0.691\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 150, 'n_features': 3}, gain: 826.00, precision: 0.690, f1: 0.683, accuracy: 0.693\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 150, 'n_features': 4}, gain: 690.00, precision: 0.692, f1: 0.685, accuracy: 0.695\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 150, 'n_features': 5}, gain: 460.00, precision: 0.699, f1: 0.692, accuracy: 0.702\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 150, 'n_features': 6}, gain: 262.00, precision: 0.695, f1: 0.693, accuracy: 0.701\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200, 'n_features': 1}, gain: 1247.60, precision: 0.689, f1: 0.687, accuracy: 0.695\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200, 'n_features': 2}, gain: 1002.60, precision: 0.676, f1: 0.675, accuracy: 0.683\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200, 'n_features': 3}, gain: 828.00, precision: 0.688, f1: 0.684, accuracy: 0.693\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200, 'n_features': 4}, gain: 695.00, precision: 0.693, f1: 0.684, accuracy: 0.695\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200, 'n_features': 5}, gain: 492.00, precision: 0.693, f1: 0.688, accuracy: 0.697\n",
      "Params: {'learning_rate': 0.1, 'max_depth': None, 'n_estimators': 200, 'n_features': 6}, gain: 254.00, precision: 0.694, f1: 0.691, accuracy: 0.699\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 50, 'n_features': 1}, gain: 1247.60, precision: 0.689, f1: 0.678, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 50, 'n_features': 2}, gain: 972.60, precision: 0.635, f1: 0.638, accuracy: 0.645\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 50, 'n_features': 3}, gain: 808.00, precision: 0.654, f1: 0.647, accuracy: 0.659\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 50, 'n_features': 4}, gain: 670.00, precision: 0.667, f1: 0.665, accuracy: 0.673\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 50, 'n_features': 5}, gain: 492.00, precision: 0.675, f1: 0.670, accuracy: 0.680\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 50, 'n_features': 6}, gain: 254.00, precision: 0.676, f1: 0.673, accuracy: 0.681\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 100, 'n_features': 1}, gain: 1247.80, precision: 0.688, f1: 0.682, accuracy: 0.692\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 100, 'n_features': 2}, gain: 970.00, precision: 0.624, f1: 0.628, accuracy: 0.634\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 100, 'n_features': 3}, gain: 798.00, precision: 0.646, f1: 0.642, accuracy: 0.652\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 100, 'n_features': 4}, gain: 672.00, precision: 0.663, f1: 0.659, accuracy: 0.669\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 100, 'n_features': 5}, gain: 492.00, precision: 0.672, f1: 0.664, accuracy: 0.675\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 100, 'n_features': 6}, gain: 260.00, precision: 0.676, f1: 0.672, accuracy: 0.681\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 150, 'n_features': 1}, gain: 1247.80, precision: 0.687, f1: 0.682, accuracy: 0.691\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 150, 'n_features': 2}, gain: 966.00, precision: 0.619, f1: 0.624, accuracy: 0.629\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 150, 'n_features': 3}, gain: 792.00, precision: 0.643, f1: 0.639, accuracy: 0.649\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 150, 'n_features': 4}, gain: 676.00, precision: 0.659, f1: 0.653, accuracy: 0.664\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 150, 'n_features': 5}, gain: 492.00, precision: 0.673, f1: 0.664, accuracy: 0.676\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 150, 'n_features': 6}, gain: 266.00, precision: 0.673, f1: 0.669, accuracy: 0.679\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 200, 'n_features': 1}, gain: 1247.80, precision: 0.687, f1: 0.682, accuracy: 0.691\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 200, 'n_features': 2}, gain: 974.00, precision: 0.614, f1: 0.618, accuracy: 0.624\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 200, 'n_features': 3}, gain: 810.00, precision: 0.637, f1: 0.632, accuracy: 0.643\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 200, 'n_features': 4}, gain: 670.00, precision: 0.658, f1: 0.653, accuracy: 0.663\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 200, 'n_features': 5}, gain: 492.00, precision: 0.667, f1: 0.659, accuracy: 0.670\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 25, 'n_estimators': 200, 'n_features': 6}, gain: 264.00, precision: 0.673, f1: 0.670, accuracy: 0.679\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 50, 'n_features': 1}, gain: 1247.60, precision: 0.689, f1: 0.678, accuracy: 0.690\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 50, 'n_features': 2}, gain: 978.00, precision: 0.659, f1: 0.660, accuracy: 0.667\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 50, 'n_features': 3}, gain: 824.00, precision: 0.673, f1: 0.664, accuracy: 0.676\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 50, 'n_features': 4}, gain: 672.00, precision: 0.678, f1: 0.674, accuracy: 0.683\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 50, 'n_features': 5}, gain: 488.00, precision: 0.691, f1: 0.682, accuracy: 0.693\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 50, 'n_features': 6}, gain: 262.00, precision: 0.689, f1: 0.685, accuracy: 0.694\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100, 'n_features': 1}, gain: 1247.00, precision: 0.687, f1: 0.682, accuracy: 0.691\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100, 'n_features': 2}, gain: 960.00, precision: 0.644, f1: 0.647, accuracy: 0.653\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100, 'n_features': 3}, gain: 816.00, precision: 0.665, f1: 0.656, accuracy: 0.668\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100, 'n_features': 4}, gain: 670.00, precision: 0.673, f1: 0.666, accuracy: 0.677\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100, 'n_features': 5}, gain: 480.00, precision: 0.680, f1: 0.671, accuracy: 0.683\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 100, 'n_features': 6}, gain: 268.00, precision: 0.688, f1: 0.684, accuracy: 0.693\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 150, 'n_features': 1}, gain: 1247.80, precision: 0.687, f1: 0.682, accuracy: 0.691\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 150, 'n_features': 2}, gain: 974.00, precision: 0.638, f1: 0.642, accuracy: 0.648\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 150, 'n_features': 3}, gain: 808.00, precision: 0.658, f1: 0.648, accuracy: 0.661\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 150, 'n_features': 4}, gain: 682.00, precision: 0.668, f1: 0.661, accuracy: 0.672\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 150, 'n_features': 5}, gain: 492.00, precision: 0.673, f1: 0.664, accuracy: 0.676\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 150, 'n_features': 6}, gain: 266.00, precision: 0.683, f1: 0.680, accuracy: 0.688\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 200, 'n_features': 1}, gain: 1247.80, precision: 0.687, f1: 0.683, accuracy: 0.692\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 200, 'n_features': 2}, gain: 970.00, precision: 0.636, f1: 0.639, accuracy: 0.646\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 200, 'n_features': 3}, gain: 814.00, precision: 0.653, f1: 0.647, accuracy: 0.658\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 200, 'n_features': 4}, gain: 676.00, precision: 0.663, f1: 0.657, accuracy: 0.668\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 200, 'n_features': 5}, gain: 490.00, precision: 0.672, f1: 0.664, accuracy: 0.675\n",
      "Params: {'learning_rate': 0.1, 'max_depth': 15, 'n_estimators': 200, 'n_features': 6}, gain: 268.00, precision: 0.682, f1: 0.677, accuracy: 0.687\n",
      "Best parameters: {'learning_rate': 0.001, 'max_depth': 25, 'n_estimators': 150, 'n_features': 1}\n",
      "Max gain: 1259.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>n_features</th>\n",
       "      <th>gain</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.001</td>\n",
       "      <td>25.0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1259.8</td>\n",
       "      <td>0.702186</td>\n",
       "      <td>0.665784</td>\n",
       "      <td>0.6898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1256.6</td>\n",
       "      <td>0.713108</td>\n",
       "      <td>0.661783</td>\n",
       "      <td>0.6920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.001</td>\n",
       "      <td>15.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1256.6</td>\n",
       "      <td>0.713108</td>\n",
       "      <td>0.661783</td>\n",
       "      <td>0.6920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1255.6</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>0.687416</td>\n",
       "      <td>0.6964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.001</td>\n",
       "      <td>15.0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>0.702186</td>\n",
       "      <td>0.665784</td>\n",
       "      <td>0.6898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.010</td>\n",
       "      <td>25.0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>0.688923</td>\n",
       "      <td>0.677620</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.010</td>\n",
       "      <td>15.0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1252.2</td>\n",
       "      <td>0.688482</td>\n",
       "      <td>0.678296</td>\n",
       "      <td>0.6902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.001</td>\n",
       "      <td>25.0</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1251.4</td>\n",
       "      <td>0.701375</td>\n",
       "      <td>0.670499</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1250.4</td>\n",
       "      <td>0.714165</td>\n",
       "      <td>0.670017</td>\n",
       "      <td>0.6964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.692322</td>\n",
       "      <td>0.689737</td>\n",
       "      <td>0.6978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     learning_rate  max_depth  n_estimators  n_features    gain  precision  \\\n",
       "36           0.001       25.0           150           1  1259.8   0.702186   \n",
       "30           0.001       25.0           100           1  1256.6   0.713108   \n",
       "54           0.001       15.0           100           1  1256.6   0.713108   \n",
       "222          0.100        NaN           100           1  1255.6   0.692001   \n",
       "60           0.001       15.0           150           1  1254.0   0.702186   \n",
       "108          0.010       25.0           150           1  1253.0   0.688923   \n",
       "132          0.010       15.0           150           1  1252.2   0.688482   \n",
       "42           0.001       25.0           200           1  1251.4   0.701375   \n",
       "6            0.001        NaN           100           1  1250.4   0.714165   \n",
       "162          0.050        NaN           200           1  1250.0   0.692322   \n",
       "\n",
       "           f1  accuracy  \n",
       "36   0.665784    0.6898  \n",
       "30   0.661783    0.6920  \n",
       "54   0.661783    0.6920  \n",
       "222  0.687416    0.6964  \n",
       "60   0.665784    0.6898  \n",
       "108  0.677620    0.6900  \n",
       "132  0.678296    0.6902  \n",
       "42   0.670499    0.6916  \n",
       "6    0.670017    0.6964  \n",
       "162  0.689737    0.6978  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 25, 15],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
    "    'n_features': [1, 2, 3, 4, 5, 6]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "best_gain = -np.inf\n",
    "best_params = None\n",
    "history = []\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    cv_gains = []\n",
    "    cv_precisions = []\n",
    "    cv_f1s = []\n",
    "    cv_accuracies = []\n",
    "    \n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx, 0], y_train.iloc[val_idx, 0]\n",
    "\n",
    "        mi = mutual_info_classif(X_tr, y_tr, random_state=42)\n",
    "        top_idx = np.argsort(mi)[::-1][:params['n_features']]\n",
    "        \n",
    "        clf = XGBClassifier(\n",
    "            n_estimators=params['n_estimators'],\n",
    "            max_depth=params['max_depth'],\n",
    "            learning_rate=params['learning_rate'],\n",
    "            eval_metric='logloss',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        clf.fit(X_tr.iloc[:, top_idx], y_tr)\n",
    "        \n",
    "        probas = clf.predict_proba(X_val.iloc[:, top_idx])[:, 1]\n",
    "        y_pred = (probas >= 0.5).astype(int)\n",
    "        \n",
    "        gain = eval_proba(probas, y_val.values, params['n_features'], num_target=200)\n",
    "        precision = precision_score(y_val, y_pred)\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        \n",
    "        cv_gains.append(gain)\n",
    "        cv_precisions.append(precision)\n",
    "        cv_f1s.append(f1)\n",
    "        cv_accuracies.append(accuracy)\n",
    "\n",
    "    avg_gain = np.mean(cv_gains)\n",
    "    avg_precision = np.mean(cv_precisions)\n",
    "    avg_f1 = np.mean(cv_f1s)\n",
    "    avg_accuracy = np.mean(cv_accuracies)\n",
    "    \n",
    "    print(f\"Params: {params}, gain: {avg_gain:.2f}, precision: {avg_precision:.3f}, f1: {avg_f1:.3f}, accuracy: {avg_accuracy:.3f}\")\n",
    "\n",
    "    history.append({**params,\n",
    "                    \"gain\": avg_gain,\n",
    "                    \"precision\": avg_precision,\n",
    "                    \"f1\": avg_f1,\n",
    "                    \"accuracy\": avg_accuracy})\n",
    "\n",
    "    if avg_gain > best_gain:\n",
    "        best_gain = avg_gain\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Max gain: {best_gain}\")\n",
    "\n",
    "history_df = pd.DataFrame(history)\n",
    "display(history_df.sort_values(\"gain\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "620343f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>n_features</th>\n",
       "      <th>gain</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.001</td>\n",
       "      <td>25.0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1259.8</td>\n",
       "      <td>0.702186</td>\n",
       "      <td>0.665784</td>\n",
       "      <td>0.6898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.001</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1256.6</td>\n",
       "      <td>0.713108</td>\n",
       "      <td>0.661783</td>\n",
       "      <td>0.6920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.001</td>\n",
       "      <td>15.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1256.6</td>\n",
       "      <td>0.713108</td>\n",
       "      <td>0.661783</td>\n",
       "      <td>0.6920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1255.6</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>0.687416</td>\n",
       "      <td>0.6964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.001</td>\n",
       "      <td>15.0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>0.702186</td>\n",
       "      <td>0.665784</td>\n",
       "      <td>0.6898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.010</td>\n",
       "      <td>25.0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>0.688923</td>\n",
       "      <td>0.677620</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.010</td>\n",
       "      <td>15.0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1252.2</td>\n",
       "      <td>0.688482</td>\n",
       "      <td>0.678296</td>\n",
       "      <td>0.6902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.001</td>\n",
       "      <td>25.0</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1251.4</td>\n",
       "      <td>0.701375</td>\n",
       "      <td>0.670499</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1250.4</td>\n",
       "      <td>0.714165</td>\n",
       "      <td>0.670017</td>\n",
       "      <td>0.6964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.692322</td>\n",
       "      <td>0.689737</td>\n",
       "      <td>0.6978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1249.4</td>\n",
       "      <td>0.705353</td>\n",
       "      <td>0.676622</td>\n",
       "      <td>0.6964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.050</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1249.2</td>\n",
       "      <td>0.688923</td>\n",
       "      <td>0.677620</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.010</td>\n",
       "      <td>25.0</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1248.2</td>\n",
       "      <td>0.688923</td>\n",
       "      <td>0.677620</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>0.692322</td>\n",
       "      <td>0.689737</td>\n",
       "      <td>0.6978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.100</td>\n",
       "      <td>15.0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1247.8</td>\n",
       "      <td>0.687419</td>\n",
       "      <td>0.681675</td>\n",
       "      <td>0.6914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.100</td>\n",
       "      <td>15.0</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1247.8</td>\n",
       "      <td>0.687180</td>\n",
       "      <td>0.683288</td>\n",
       "      <td>0.6922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.050</td>\n",
       "      <td>25.0</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1247.8</td>\n",
       "      <td>0.687393</td>\n",
       "      <td>0.681691</td>\n",
       "      <td>0.6914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.100</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1247.8</td>\n",
       "      <td>0.687823</td>\n",
       "      <td>0.681691</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.100</td>\n",
       "      <td>25.0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1247.8</td>\n",
       "      <td>0.687393</td>\n",
       "      <td>0.681691</td>\n",
       "      <td>0.6914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0.100</td>\n",
       "      <td>25.0</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1247.8</td>\n",
       "      <td>0.687393</td>\n",
       "      <td>0.681691</td>\n",
       "      <td>0.6914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.050</td>\n",
       "      <td>15.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1247.6</td>\n",
       "      <td>0.689193</td>\n",
       "      <td>0.678178</td>\n",
       "      <td>0.6904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.100</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1247.6</td>\n",
       "      <td>0.688923</td>\n",
       "      <td>0.677620</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1247.6</td>\n",
       "      <td>0.688940</td>\n",
       "      <td>0.687127</td>\n",
       "      <td>0.6950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.100</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1247.6</td>\n",
       "      <td>0.688923</td>\n",
       "      <td>0.677620</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1247.6</td>\n",
       "      <td>0.708700</td>\n",
       "      <td>0.673613</td>\n",
       "      <td>0.6962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.050</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1247.2</td>\n",
       "      <td>0.688923</td>\n",
       "      <td>0.677620</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.001</td>\n",
       "      <td>15.0</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1247.2</td>\n",
       "      <td>0.701375</td>\n",
       "      <td>0.670499</td>\n",
       "      <td>0.6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.100</td>\n",
       "      <td>15.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>0.687419</td>\n",
       "      <td>0.681675</td>\n",
       "      <td>0.6914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.050</td>\n",
       "      <td>15.0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1246.8</td>\n",
       "      <td>0.687703</td>\n",
       "      <td>0.679446</td>\n",
       "      <td>0.6904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.050</td>\n",
       "      <td>15.0</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1246.2</td>\n",
       "      <td>0.687419</td>\n",
       "      <td>0.681675</td>\n",
       "      <td>0.6914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.050</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1246.2</td>\n",
       "      <td>0.688923</td>\n",
       "      <td>0.677620</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.050</td>\n",
       "      <td>25.0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1246.2</td>\n",
       "      <td>0.688943</td>\n",
       "      <td>0.679940</td>\n",
       "      <td>0.6912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.010</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1246.0</td>\n",
       "      <td>0.688482</td>\n",
       "      <td>0.678296</td>\n",
       "      <td>0.6902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1245.8</td>\n",
       "      <td>0.691807</td>\n",
       "      <td>0.687785</td>\n",
       "      <td>0.6966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.010</td>\n",
       "      <td>15.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1245.6</td>\n",
       "      <td>0.688482</td>\n",
       "      <td>0.678296</td>\n",
       "      <td>0.6902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.010</td>\n",
       "      <td>15.0</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1245.6</td>\n",
       "      <td>0.688482</td>\n",
       "      <td>0.678296</td>\n",
       "      <td>0.6902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1237.2</td>\n",
       "      <td>0.695240</td>\n",
       "      <td>0.684592</td>\n",
       "      <td>0.6964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.001</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1236.4</td>\n",
       "      <td>0.714440</td>\n",
       "      <td>0.520569</td>\n",
       "      <td>0.6374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1236.4</td>\n",
       "      <td>0.714440</td>\n",
       "      <td>0.520569</td>\n",
       "      <td>0.6374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>0.692885</td>\n",
       "      <td>0.689256</td>\n",
       "      <td>0.6978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1234.6</td>\n",
       "      <td>0.694088</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>0.6986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1234.4</td>\n",
       "      <td>0.699602</td>\n",
       "      <td>0.681754</td>\n",
       "      <td>0.6968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1233.8</td>\n",
       "      <td>0.694127</td>\n",
       "      <td>0.689005</td>\n",
       "      <td>0.6982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1230.6</td>\n",
       "      <td>0.692322</td>\n",
       "      <td>0.689737</td>\n",
       "      <td>0.6978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1227.0</td>\n",
       "      <td>0.711801</td>\n",
       "      <td>0.498144</td>\n",
       "      <td>0.6296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.698898</td>\n",
       "      <td>0.684364</td>\n",
       "      <td>0.6978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.010</td>\n",
       "      <td>25.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>0.688788</td>\n",
       "      <td>0.678006</td>\n",
       "      <td>0.6902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.010</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>0.688788</td>\n",
       "      <td>0.678006</td>\n",
       "      <td>0.6902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>0.719042</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.6332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>0.711348</td>\n",
       "      <td>0.656725</td>\n",
       "      <td>0.6886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     learning_rate  max_depth  n_estimators  n_features    gain  precision  \\\n",
       "36           0.001       25.0           150           1  1259.8   0.702186   \n",
       "30           0.001       25.0           100           1  1256.6   0.713108   \n",
       "54           0.001       15.0           100           1  1256.6   0.713108   \n",
       "222          0.100        NaN           100           1  1255.6   0.692001   \n",
       "60           0.001       15.0           150           1  1254.0   0.702186   \n",
       "108          0.010       25.0           150           1  1253.0   0.688923   \n",
       "132          0.010       15.0           150           1  1252.2   0.688482   \n",
       "42           0.001       25.0           200           1  1251.4   0.701375   \n",
       "6            0.001        NaN           100           1  1250.4   0.714165   \n",
       "162          0.050        NaN           200           1  1250.0   0.692322   \n",
       "18           0.001        NaN           200           1  1249.4   0.705353   \n",
       "168          0.050       25.0            50           1  1249.2   0.688923   \n",
       "114          0.010       25.0           200           1  1248.2   0.688923   \n",
       "156          0.050        NaN           150           1  1248.0   0.692322   \n",
       "276          0.100       15.0           150           1  1247.8   0.687419   \n",
       "282          0.100       15.0           200           1  1247.8   0.687180   \n",
       "186          0.050       25.0           200           1  1247.8   0.687393   \n",
       "246          0.100       25.0           100           1  1247.8   0.687823   \n",
       "252          0.100       25.0           150           1  1247.8   0.687393   \n",
       "258          0.100       25.0           200           1  1247.8   0.687393   \n",
       "198          0.050       15.0           100           1  1247.6   0.689193   \n",
       "240          0.100       25.0            50           1  1247.6   0.688923   \n",
       "234          0.100        NaN           200           1  1247.6   0.688940   \n",
       "264          0.100       15.0            50           1  1247.6   0.688923   \n",
       "12           0.001        NaN           150           1  1247.6   0.708700   \n",
       "192          0.050       15.0            50           1  1247.2   0.688923   \n",
       "66           0.001       15.0           200           1  1247.2   0.701375   \n",
       "270          0.100       15.0           100           1  1247.0   0.687419   \n",
       "204          0.050       15.0           150           1  1246.8   0.687703   \n",
       "210          0.050       15.0           200           1  1246.2   0.687419   \n",
       "174          0.050       25.0           100           1  1246.2   0.688923   \n",
       "180          0.050       25.0           150           1  1246.2   0.688943   \n",
       "102          0.010       25.0           100           1  1246.0   0.688482   \n",
       "228          0.100        NaN           150           1  1245.8   0.691807   \n",
       "126          0.010       15.0           100           1  1245.6   0.688482   \n",
       "138          0.010       15.0           200           1  1245.6   0.688482   \n",
       "84           0.010        NaN           150           1  1237.2   0.695240   \n",
       "48           0.001       15.0            50           1  1236.4   0.714440   \n",
       "24           0.001       25.0            50           1  1236.4   0.714440   \n",
       "216          0.100        NaN            50           1  1235.0   0.692885   \n",
       "90           0.010        NaN           200           1  1234.6   0.694088   \n",
       "72           0.010        NaN            50           1  1234.4   0.699602   \n",
       "144          0.050        NaN            50           1  1233.8   0.694127   \n",
       "150          0.050        NaN           100           1  1230.6   0.692322   \n",
       "0            0.001        NaN            50           1  1227.0   0.711801   \n",
       "78           0.010        NaN           100           1  1218.0   0.698898   \n",
       "96           0.010       25.0            50           1  1213.0   0.688788   \n",
       "120          0.010       15.0            50           1  1208.0   0.688788   \n",
       "1            0.001        NaN            50           2  1057.0   0.719042   \n",
       "7            0.001        NaN           100           2  1056.0   0.711348   \n",
       "\n",
       "           f1  accuracy  \n",
       "36   0.665784    0.6898  \n",
       "30   0.661783    0.6920  \n",
       "54   0.661783    0.6920  \n",
       "222  0.687416    0.6964  \n",
       "60   0.665784    0.6898  \n",
       "108  0.677620    0.6900  \n",
       "132  0.678296    0.6902  \n",
       "42   0.670499    0.6916  \n",
       "6    0.670017    0.6964  \n",
       "162  0.689737    0.6978  \n",
       "18   0.676622    0.6964  \n",
       "168  0.677620    0.6900  \n",
       "114  0.677620    0.6900  \n",
       "156  0.689737    0.6978  \n",
       "276  0.681675    0.6914  \n",
       "282  0.683288    0.6922  \n",
       "186  0.681691    0.6914  \n",
       "246  0.681691    0.6916  \n",
       "252  0.681691    0.6914  \n",
       "258  0.681691    0.6914  \n",
       "198  0.678178    0.6904  \n",
       "240  0.677620    0.6900  \n",
       "234  0.687127    0.6950  \n",
       "264  0.677620    0.6900  \n",
       "12   0.673613    0.6962  \n",
       "192  0.677620    0.6900  \n",
       "66   0.670499    0.6916  \n",
       "270  0.681675    0.6914  \n",
       "204  0.679446    0.6904  \n",
       "210  0.681675    0.6914  \n",
       "174  0.677620    0.6900  \n",
       "180  0.679940    0.6912  \n",
       "102  0.678296    0.6902  \n",
       "228  0.687785    0.6966  \n",
       "126  0.678296    0.6902  \n",
       "138  0.678296    0.6902  \n",
       "84   0.684592    0.6964  \n",
       "48   0.520569    0.6374  \n",
       "24   0.520569    0.6374  \n",
       "216  0.689256    0.6978  \n",
       "90   0.689799    0.6986  \n",
       "72   0.681754    0.6968  \n",
       "144  0.689005    0.6982  \n",
       "150  0.689737    0.6978  \n",
       "0    0.498144    0.6296  \n",
       "78   0.684364    0.6978  \n",
       "96   0.678006    0.6902  \n",
       "120  0.678006    0.6902  \n",
       "1    0.518100    0.6332  \n",
       "7    0.656725    0.6886  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(history_df.sort_values(\"gain\", ascending=False).head(50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
